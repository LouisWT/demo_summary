## 1. 事件循环线程与工作线程池的线程
Node 是用很少的线程来处理大量客户端请求的。

Node中，有两种类型的线程，一个事件循环线程(也就是主线程、事件线程)。另外就是在工作线程池里的 k 个工作线程。

如果一个线程执行一个回调函数（事件轮询线程）或者任务（工作线程）需要耗费很长时间，我们称之为“阻塞”。 当一个线程在处理某一个客户端请求时被阻塞了，它就无法处理其它客户端的请求了。

事件循环线程和工作线程都不能阻塞，否则会有性能和安全性问题：
- 性能： 如果在任意类型的线程上频繁处理繁重的任务，那么服务器的吞吐量会减少，而且可能是大大减少
- 安全性：如果对于特定输入，某种类型线程可能被阻塞，那么攻击者可以通过构造类似这样的恶意输入故意让线程阻塞，这样其他客户端的请求得不到响应，就是拒绝服务攻击了


## 2. 运行在事件循环线程(主线程)上的代码
1. 当 Node 程序运行时，程序首先完成初始化部分，即处理 require 加载的模块和注册事件回调。 
2. 然后，Node 应用程序进入事件循环阶段，通过执行对应回调函数来对客户端请求做出回应。 
3. 此回调将同步执行，并且可能在完成之后继续注册新的异步请求。 这些异步请求的回调也会在事件轮询线程中被处理。

事件循环线程执行事件的回调函数，并且负责处理类似网络I/O的非阻塞异步请求

## 3. 运行在工作线程池的代码

Node 的工作线程池是通过 libuv (相关文档) 来实现的，它对外提供了一个通用的任务处理 API。

Node 使用工作线程池来处理高成本的任务，包括一些操作系统没有提供的非阻塞版本的 IO 操作，以及一些 CPU 密集型任务。

如下API用到了工作线程池：
- IO密集型任务
  1. DNS: dns.lookup(), dns.lookupService()
  2. 文件系统，所有文件系统 API，除了 fs.FSWatcher() 和显式同步调用的 API，都使用 libuv 的线程池
- CPU 密集型任务
  1. Crypto: crypto.pbkdf2()，crypto.randomBytes()，crypto.randomFill()
  2. Zilb: 所有 Zlib 相关函数，除那些显式同步调用的 API 之外，都适用 libuv 的线程池。


当你在事件轮询线程的一个回调中调用这些 API 时，事件轮询线程将不得不为此花费少量的额外开销，因为它必须要进入对应 API 与 C++ 桥接通讯的 Node C++ binding 中，从而向工作线程池提交一个任务。 和整个任务的成本相比，这些开销微不足道。

## 4. Node如何决定下一步运行哪些代码
事件轮询线程和工作池线程分别为等待中的事件回调和等待中的任务维护一个队列。

## 5. Node 应用设计
### 5.1 对任意一个客户端，不应在一个回调或任务中做太多事
Node 用少量的线程处理许多客户端连接，如果在处理某个客户端的时候阻塞了，在该客户端请求的回调或任务完成之前，其他等待中的任务可能都不会得到执行机会。 因此，保证每个客户端请求得到公平的执行机会变成了应用程序的责任。 这意味着，对于任意一个客户端，你不应该在一个回调或任务中做太多的事情。

### 5.2 不要阻塞事件轮询线程(主线程)
事件循环线程关注每个新的客户端连接，协调产生一个回应，所有进入的请求和输出的应答都要通过事件轮询线程，所以如果事件循环线程在某个地方花费了太多事件，所有当前和未来新的客户端请求都得不到处理机会

所以应当保证每个 JS 回调都能尽快完成。

最好的办法就是分析回调代码的计算复杂度，如果你的回调函数在任意的参数输入下执行步骤数量都相同，那么你总能保证每个等待中的请求得到一个公平的执行机会。 如果回调根据其参数不同所需要的执行步骤数量也不同， 则应深入考虑参数复杂度增长的情况下请求的可能执行时间增长情况。

对于复杂的任务，限定输入范围，拒绝会导致太长执行时间的输入。

阻塞事件轮询的常用错误：
#### 1. REDOS(有漏洞的正则表达式)阻塞事件轮询
在某些情况下，正则表达式匹配扫描随着输入字符串呈指数增长——时间是 O(2^n)。 指数级的扫描时间消耗意味着如果引擎需要 x 时间来确定匹配；我们的输入仅仅只增加一个字符，它将需要 2 * x 的时间。 由于扫描的消耗与所需时间呈线性关系，因此，这种正则匹配将阻塞事件循环

避免使用有漏洞的正则：
- 避免嵌套量词，如 `(a+)*`
- 避免带有“或”的重叠情况，如`(a|a)*`
- 避免使用回溯，如 `(a.*) \1`
- 如果只做简单的字符串匹配，使用 `indexOf` 之类的等价 API

解决办法：
- 使用工具检查正则表达式是否安全：[safe-regex](https://github.com/substack/safe-regex)
- 使用 [node-re2](https://github.com/uhop/node-re2)

#### 2. 某些Node核心模块阻塞事件轮询
以下模块有同步的高开销方法：
- crypto 加密：`crypto.randomBytes crypto.randomFillSync crypto.pbkdf2Sync`、小心对大数据输入的加密解密情况
- zlib 压缩： `zlib.inflateSync zlib.deflateSync`
- fs 文件系统：不适用API的 sync 版本
- child_process 子进程：`child_process.spawnSync child_process.execSync child_process.execFileSync`

#### 3. JSON parse stringify 阻塞事件轮询
JSON.parse 以及 JSON.stringify 是其它潜在高开销的操作。 这些操作的复杂度是 O(n) ，对于大型的 n 输入，消耗的时间可能惊人的长。

#### 4. 复杂计算阻塞舌尖轮询

如果想在 JS 中处理一个复杂计算，而不想阻塞事件循环，可以使用任务拆分或者任务分流

1. 任务拆分,
把复杂计算拆开，不让它运行在同一次事件循环中
```js
for (let i = 0; i < n; i++) {
  sum += i;
}
let avg = sum / n;
console.log(avg);

// 任务拆分后
function asyncAvg(n, avgCB) {
  let sum = 0;
  function help(i, cb) {
    sum += i;
    if (i == n) {
      cb(sum);
    }
    return;
  }

  setImmediate(help.bind(null, i + 1, cb));

  help(1, function(sum) {
    let avg = sum / n;
    avgCB(avg);
  })
}

asyncAvg(n, function (avg) {
  console.log(avg);
})
```

2. 任务分流

对一个复杂的任务，最好把它从事件循环线程转移到工作线程池上。

将任务从事件循环线程移到工作线程池的方法：
- 使用Node C++ 拓展
- 使用 child process 或者 cluster

对于简单的任务：比如遍历任意长数组的元素，拆分可能是一个很好的选择。 

如果计算更加复杂，则分流是一种更好的方法：通信成本（即在事件循环线程和工作线程之间传递序列化对象的开销）被使用多个物理内核的好处抵消。

但是，如果你的服务器严重依赖复杂的计算，则应该重新考虑 Node 是否真的很适合该场景？Node 擅长于 I/O 密集型任务，但对于昂贵的计算，它可能不是最好的选择。

### 5.3 不要阻塞工作线程池
如果工作线程的当前任务比其它任务开销大很多，则他无法处理其它等待中任务。 换言之，每个相对长的任务会直接减少了工作线程池的可用线程数量，直到它的任务完成。 这是不可取的。因为从某种程度上说，工作池中的工作线程越多，工作池吞吐量（任务/秒）就越大，因此服务器吞吐量（客户端请求/秒）就越大。 一个具有相对昂贵开销任务的客户端请求将减少工作线程池整体的吞吐量，从而降低服务器的吞吐量。


## 6. 总结
Node 有两种类型的线程，一个事件循环线程和 k 个工作线程。事件循环负责 JS 回调和非阻塞 IO(比如网络 IO)，工作线程执行一些阻塞 IO 和 CPU密集型工作，这两种类型的线程一次只能处理一个活动。如果任意一个回调或者任务需要很长时间，那么它的线程将被阻塞。好的情况下，这只会导致吞吐量下降，最坏情况会导致完全拒绝服务

**要编写高吞吐量、防 DoS 攻击的 web 服务，您必须确保不管在良性或恶意输入的情况下，您的事件循环线程和您的工作线程都不会阻塞。**